platform.local.dist=C:\\mydoc\\myprojects\\bdap\\bdap-VVERSIONN\\engine
platform.remote.lib=/bdap-VVERSIONN/engine/lib
platform.coordinate.xml=/bdap-VVERSIONN/cfg/coordinator.xml
platform.spark.wfxml=/bdap-VVERSIONN/cfg/sparkcmd_workflow.xml
projects=project1
project1.local.dir=C:\\mydoc\\myprojects\\bdap\\bdap-mgr\\src\\test\\resources\\
project1.hdfs.dir=/project1/

hdfs.user=hdfs

#oozie config
oozie.server.ip=192.85.246.17
oozie.server.port=11000
nameNode=hdfs://192.85.246.17:8020
jobTracker=192.85.246.17:8032
user.name=mapred

#spark config
jdk.bin=C:\\dev\\Java\\jdk1.8.0_60\\bin
tmp.dir=C:\\tmp

#engine config
defaultFs=hdfs://192.85.246.17:8020

kafka.enabled=false

#db.type=hive
#db.driver=org.apache.hive.jdbc.HiveDriver
#db.url=jdbc:hive2://192.85.246.17:10000/
#db.user=dbadmin
#db.password=password


db.type=hive
db.driver=com.cloudera.impala.jdbc41.Driver
db.url=jdbc:impala://192.85.246.17:21050/
db.user=dbadmin
db.password=password

hdfs.webhdfs.root=

zookeeper.url=192.85.246.17:2181